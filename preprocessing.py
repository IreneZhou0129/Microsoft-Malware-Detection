#!/usr/bin/env python
# coding: utf-8

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from tqdm import tqdm
from sklearn.impute import SimpleImputer
import sys
from sklearn.preprocessing import LabelEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.decomposition import PCA
import warnings

import time
warnings.filterwarnings('ignore')

# ====================================================================
# Read the file
# ====================================================================
start = time.time()

df_tmp = []
for chunk in tqdm(pd.read_csv('train.csv', chunksize=20000, low_memory=False)):
    df_tmp.append(chunk)
train_df = pd.concat(df_tmp, axis=0)
del df_tmp

end = time.time()
print('read file in ', (end - start))


# ====================================================================
# Drop rows and columns
# ====================================================================
# Row
# Find the row has too much null values, include the label, drop this row
train_df = train_df.drop([2243047])


# Columns
train_df.drop(['PuaMode',
               'Census_ProcessorClass',
               'DefaultBrowsersIdentifier',
               'Census_InternalBatteryType',
               'Census_IsFlightingInternal',
               'Census_ThresholdOptIn',
               'Census_IsWIMBootEnabled'],
              axis=1,
              inplace=True)


# Impute the null values in the column RtpStateBitfield

most_frequent_imp = SimpleImputer(strategy="most_frequent")
train_df['RtpStateBitfield'] = most_frequent_imp.fit_transform(
    train_df[['RtpStateBitfield']])


# Handle three Anti-virus product related columns
avnans = train_df.loc[(train_df['AVProductStatesIdentifier'].isnull()) &
                      (train_df['AVProductsInstalled'].isnull()) &
                      (train_df['AVProductsEnabled'].isnull())]


# Fill null with maximum occuring value
train_df['AVProductStatesIdentifier'] = most_frequent_imp.fit_transform(
    train_df[['AVProductStatesIdentifier']])

train_df['AVProductsInstalled'] = most_frequent_imp.fit_transform(
    train_df[['AVProductsInstalled']])

train_df['AVProductsEnabled'] = most_frequent_imp.fit_transform(
    train_df[['AVProductsEnabled']])

# see the result
avnans2 = train_df.loc[(train_df['AVProductStatesIdentifier'].isnull()) &
                       (train_df['AVProductsInstalled'].isnull()) &
                       (train_df['AVProductsEnabled'].isnull())]


# Handle City ID start

# Dataframe that has null values in the column CityIdentifier
null_cities = train_df.loc[(train_df['CityIdentifier'].isnull())]

# given country ID, find the most frequent city's ID


def find_max_city(countryID, df):
    cities = df.loc[(df['CountryIdentifier'] == countryID)]
    cityID = cities['CityIdentifier'].value_counts().idxmax()
    return cityID

# Create a dictionary has key: countryID, value: corresponding most
# frequent city's ID


def most_city_dict(df):

    #     find all country IDs, there are 222 countries
    country_groups = df.groupby('CountryIdentifier')

    # type: dict
    all_country_dict = country_groups.groups

#     copy keys from the original dict to my dict
    my_dict = dict.fromkeys(all_country_dict)

#     assign the city's ID to the country
    for k, v in my_dict.items():
        my_dict[k] = find_max_city(k, df)

    return my_dict


cityIDdic = most_city_dict(train_df)


# Given the country ID, return the city ID based on the dict created above
def find_city(country, city):
    if np.isnan(city):
        return cityIDdic[country]
    return city


# iterate the df and fill the null values
train_df['CityIdentifier'] = train_df.CountryIdentifier.combine(
    train_df.CityIdentifier,
    find_city)

# Handle City ID end


# KNN model

org_train_df = train_df.loc[(train_df['OrganizationIdentifier'].notnull())]

# creating labelEncoder
le = LabelEncoder()

# convert string labels into numbers

# Encode Product Name:
le.fit(org_train_df['ProductName'])
pdName_encoded = le.transform(org_train_df['ProductName'])

# Encode Engine Version:
le.fit(org_train_df['EngineVersion'])
ev_encoded = le.transform(org_train_df['EngineVersion'])

# Encode App Version:
le.fit(org_train_df['AppVersion'])
app_encoded = le.transform(org_train_df['AppVersion'])

# Encode AvSigVersion:
le.fit(org_train_df['AvSigVersion'])
avsig_encoded = le.transform(org_train_df['AvSigVersion'])

# Encode CountryIdentifier
le.fit(org_train_df['CountryIdentifier'])
coun_encoded = le.transform(org_train_df['CountryIdentifier'])


# Encode the OrganizationIdentifier:
le.fit(org_train_df['OrganizationIdentifier'])
org_encoded = le.transform(org_train_df['OrganizationIdentifier'])


# combine multiple columns into a single set of data
org_features = list(zip(pdName_encoded,
                        ev_encoded,
                        app_encoded,
                        avsig_encoded,
                        coun_encoded))

# build KNN classifier model
knn_model = KNeighborsClassifier()

# train the model using the training sets
knn_model.fit(org_features, org_encoded)


# Encode all columns needed
orgPredDf = train_df.loc[(train_df['OrganizationIdentifier'].isnull())]

orgPreIndex = orgPredDf.index.values
pName = le.fit_transform(orgPredDf['ProductName'])
env = le.fit_transform(orgPredDf['EngineVersion'])
appv = le.fit_transform(orgPredDf['AppVersion'])
avsig = le.fit_transform(orgPredDf['AvSigVersion'])
cID = le.fit_transform(orgPredDf['CountryIdentifier'])

preOrgFeatures = list(zip(orgPreIndex,
                          pName,
                          env,
                          appv,
                          avsig,
                          cID))


# convert the list of tuples into a dictionary
preOrgDict = {i[0]: i[1:] for i in preOrgFeatures}


# select rows by index(key)

for key, val in preOrgDict.items():

    currRow = train_df.loc[key, :]

#     obtain the list of features
    list_features = list(val)

#     predict the orgID for current machine
    curr_orgID = knn_model.predict([list_features])

    train_df.at[key, 'OrganizationIdentifier'] = curr_orgID


# given the country ID, find the most frequent GeoNameID

def find_max_geo(countryID, df):

    geos = df.loc[(df['CountryIdentifier'] == countryID)]
    geoID = geos['GeoNameIdentifier'].value_counts().idxmax()

    return geoID


# handle GeoNameIdentifier column
geo_nulls = train_df.loc[train_df['GeoNameIdentifier'].isnull()]

# get the indexs of rows contain the null values in the GeoNameId column
geo_null_indexes = geo_nulls.index.values

geoNullId_size = len(geo_null_indexes)

# iterate all rows with null values in the GeoNameId column
for i in range(geoNullId_size):

    #     Current index
    currIndex = geo_null_indexes[i]

#     obtain the current Country Id
    currCountry = train_df.iloc[i]['CountryIdentifier']

#     find the corresponding GeoNameId
    currGeoId = find_max_geo(currCountry, train_df)

#     assign this GeoNameId to the current row
    train_df.at[currIndex, 'GeoNameIdentifier'] = currGeoId


# handle OsBuildLab null values: only 4 rows

# for the row with index: 70087
osB_1 = train_df.loc[(train_df['ProductName'] == 'win8defender') &
                     (train_df['EngineVersion'] == '1.1.15300.5') &
                     (train_df['AppVersion'] == '4.18.1807.18075') &
                     (train_df['AvSigVersion'] == '1.275.1487.0') &
                     (train_df['IsBeta'] == 0)]

# get the most frequent value in this column
osB_1_ser = osB_1['OsBuildLab'].mode()

# obtain the string
osB_1_val = osB_1_ser[0]
train_df.at[70087, 'OsBuildLab'] = osB_1_val

# for the row with index: 988555
osB_3 = train_df.loc[(train_df['ProductName'] == 'win8defender') &
                     (train_df['EngineVersion'] == '1.1.15100.1') &
                     (train_df['AppVersion'] == '4.18.1807.18075') &
                     (train_df['AvSigVersion'] == '1.273.1613.0') &
                     (train_df['IsBeta'] == 0)]

osB_3_ser = osB_3['OsBuildLab'].mode()

osB_3_val = osB_3_ser[0]
train_df.at[988555, 'OsBuildLab'] = osB_3_val

# the rows with index: 587482 and 1485217 are the only two don't have
# OsBuildLab
mostOBL = train_df['OsBuildLab'].mode()
train_df.at[587482, 'OsBuildLab'] = mostOBL.values
train_df.at[1485217, 'OsBuildLab'] = mostOBL.values


# handle IsProtected null values
# Since null has meaning in this column, an independent category
# replace it with number 2
train_df['IsProtected'].fillna(2, inplace=True)


# handle SMode
# 0.0   2107371
# 1.0       913 <-> OsVer = 10.0.0.0

# Handling the rows with OsVer = 10.0.0.0
ver10_nulls = train_df.loc[(train_df['SMode'].isnull()) &
                           (train_df['OsVer'] == '10.0.0.0')
                           ]

ver10N_indexs = ver10_nulls.index.values
ver10N_id_size = len(ver10N_indexs)

for i in range(ver10N_id_size):
    currIndex = ver10N_indexs[i]
    train_df.at[currIndex, 'SMode'] = 1.0


# Handling the rows with OsVer not equal to 10.0.0.0
other_nulls = train_df.loc[(train_df['SMode'].isnull()) &
                           (train_df['OsVer'] != '10.0.0.0')
                           ]

otherN_indexs = other_nulls.index.values
otherN_id_size = len(otherN_indexs)

for i in range(otherN_id_size):
    currIndex = otherN_indexs[i]
    train_df.at[currIndex, 'SMode'] = 1.0


# handle IeVerIdentifier
train_df['IeVerIdentifier'] = most_frequent_imp.fit_transform(
    train_df[['IeVerIdentifier']])


# replace word
def replace_word(old, goal):
    df = train_df.loc[train_df['SmartScreen'] == old]
    df_index = df.index.values
    df_size = len(df_index)

    for i in range(df_size):
        currIndex = df_index[i]
        train_df.at[currIndex, 'SmartScreen'] = goal


# handle SmartScreen (1)
# Unify value's names first
# =====
replace_word('requireadmin', 'RequireAdmin')
replace_word('OFF', 'off')
replace_word('off', 'Off')
replace_word('Promt', 'Prompt')
replace_word('on', 'On')

# my assumption
replace_word('0', 'Off')
# =====


# handle SmartScreen (2)
train_df['SmartScreen'].fillna('ExistsNotSet', inplace=True)


# handle firewall
train_df['Firewall'].fillna(1.0, inplace=True)


# handle UacLuaenable
train_df['UacLuaenable'].fillna(1.0, inplace=True)


# modify the format of the column OsBuildLab, for the future encode step

train_df['OsBuildLab'] = train_df['OsBuildLab'].apply(
    lambda x: x if isinstance(x, str) else str(x[0]))

for i in train_df['OsBuildLab'].values:
    if not isinstance(i, str):
        print(i, type(i))
osble = LabelEncoder()

train_df['OsBuildLab'] = osble.fit_transform(train_df['OsBuildLab'])


# Calculate a randome value based on
# the current column's value distribution

def random_fill(df_col):

    # get the frequencies for this column
    frequencies = df_col.value_counts()

    # get the ID column
    identifiers = frequencies.index

    # get the number of rows without null values
    notnull_rows = df_col.notnull().sum()

    # calculate the distribution for each value
    distributions = (frequencies / notnull_rows).tolist()

    random_value = np.random.choice(identifiers,
                                    1,
                                    p=distributions)

    return random_value


# Create a functon used to fill null values
# in one column based on the above function

def fill_allNull(df_col):

    # replace all null values with 8888
    fill8 = df_col.fillna(8888)

    # replace all 8888 with the random value that is calculated above
    randomVal = (random_fill(df_col))[0]

    res = fill8.replace(8888, randomVal)

    return res


# ====================================================
# Fill null values in other columns
# ====================================================
col1 = 'Census_OEMNameIdentifier'
col2 = 'Census_OEMModelIdentifier'

train_df[col1] = fill_allNull(train_df[col1])
train_df[col2] = fill_allNull(train_df[col2])


col3 = 'Census_ProcessorCoreCount'
train_df[col3] = fill_allNull(train_df[col3])


col4 = 'Census_ProcessorManufacturerIdentifier'
train_df[col4] = fill_allNull(train_df[col4])


col5 = 'Census_ProcessorModelIdentifier'

train_df[col5] = fill_allNull(train_df[col5])


col6 = 'Census_PrimaryDiskTotalCapacity'

train_df[col6] = fill_allNull(train_df[col6])


col7 = 'Census_PrimaryDiskTypeName'

# combine Unspecified and UNKNOWN together
train_df[col7] = train_df[col7].replace('Unspecified', 'UNKNOWN')

# encode HDD = 1; SSD= 2; UNKNOWN = 3
train_df[col7] = train_df[col7].replace('HDD', 1)
train_df[col7] = train_df[col7].replace('SSD', 2)
train_df[col7] = train_df[col7].replace('UNKNOWN', 3)

# fill null with random value
train_df[col7] = fill_allNull(train_df[col7])


col8 = 'Census_SystemVolumeTotalCapacity'
train_df[col8] = fill_allNull(train_df[col8])


col9 = 'Census_TotalPhysicalRAM'
train_df[col9] = fill_allNull(train_df[col9])


col10 = 'Census_ChassisTypeName'

replace_word = {'Unknown': 'UNKNOWN',
                '0': 'UNKNOWN',
                '25': 'MultisystemChassis',
                '28': 'Blade',
                '30': 'Tablet',
                '31': 'Convertible',
                '32': 'Detachable',
                '35': 'MiniPC',
                '36': 'StickPC'}


# obtain the train_df[col10]
train_df[col10] = train_df2[col10]

# save all values into a tmp
tmp = (train_df[col10]).to_frame()

# do the replacement on tmp
tmp.replace({col10: replace_word}, inplace=True)

# assign values in tmp back to the column in train_df
train_df[col10] = tmp

# fill null values randomly
train_df[col10] = fill_allNull(train_df[col10])


col11 = 'Census_InternalPrimaryDiagonalDisplaySizeInInches'
train_df[col11] = fill_allNull(train_df[col11])


col12 = 'Census_InternalPrimaryDisplayResolutionHorizontal'

train_df[col12] = fill_allNull(train_df[col12])


col13 = 'Census_InternalPrimaryDisplayResolutionVertical'

train_df[col13] = fill_allNull(train_df[col13])


col14 = 'Census_PowerPlatformRoleName'
train_df[col14] = fill_allNull(train_df[col14])


col15 = 'Census_InternalBatteryNumberOfCharges'
train_df[col15] = fill_allNull(train_df[col15])


col16 = 'Census_OSInstallLanguageIdentifier'
train_df[col16] = fill_allNull(train_df[col16])


col17 = 'Census_IsFlightsDisabled'
train_df[col17] = fill_allNull(train_df[col17])


col18 = 'Census_FirmwareManufacturerIdentifier'
train_df[col18] = fill_allNull(train_df[col18])


col19 = 'Census_FirmwareVersionIdentifier'

train_df[col19] = fill_allNull(train_df[col19])


col20 = 'Census_IsVirtualDevice'
train_df[col20] = fill_allNull(train_df[col20])


col21 = 'Census_IsAlwaysOnAlwaysConnectedCapable'

train_df[col21] = fill_allNull(train_df[col21])


col22 = 'Wdft_IsGamer'
train_df[col22] = fill_allNull(train_df[col22])


col23 = 'Wdft_RegionIdentifier'
train_df[col23] = fill_allNull(train_df[col23])


# drop the last row: all null values
train_df.drop(test.tail(1).index, inplace=True)

# =================================================
# Up to now, the table doesn't have any null values
# anymore.
# Next I'm going to encode all values:
# any type --> integer labeled
# =================================================


# encoded all columns

# select all columns except the last one: HasDetected
encoded_df = train_df[train_df.columns[:-1]]

train_le = LabelEncoder()


def func(x): return x.values if isinstance(x, pd.Series) else x


encoded_df = encoded_df.apply(func)

for col in encoded_df.columns:
    type_id = None
    encoded_df[col] = train_le.fit_transform(encoded_df[col])
    print('done: ', col)


# Concatenate the last column: HasDetected to the current df
groundTruth = (train_df.iloc[:, -1]).to_frame()
newDF = pd.concat([encoded_df, groundTruth], axis=1, sort=False)


# Save the new dataframe into two csv files:
# one for training, another one for testing
testdf = newDF
every3 = testdf.loc[(testdf.index % 3 == 0)]


every3.to_csv(r'my_train.csv', index=None, header=True)


every3_left = testdf.loc[(testdf.index % 3 != 0)]


every3_left.to_csv(r'my_test.csv', index=None, header=True)
